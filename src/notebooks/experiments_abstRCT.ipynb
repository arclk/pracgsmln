{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments_abstRCT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnMf7Vl8tSY_"
      },
      "source": [
        "import copy\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report, cohen_kappa_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPyfoUAtUi2",
        "outputId": "bffaccad-ec73-428f-aa3e-d9c0fea8124e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-7_BI5y6mqe"
      },
      "source": [
        "device = \"cpu\"\n",
        "base_dir = \"..\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmNe2YOi33Ue"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BacszTVu2MJ6"
      },
      "source": [
        "### neoplasm25"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laod all the variables used in the learning algorithm:\n",
        "\n",
        "\n",
        "*   **var_dict** is the dictionary of all the variables grounded from the MRF (14086 for the predicate Link, 2246 for the predicate Text, 2246 for the predicate Type) \n",
        "*   **nn_inputs** contains the inputs of the neural networks\n",
        "*   **gidx_mat** is a matrix used to link the variable of the predicate Text to the variable of the predicate Link (because it takes in input two Text)\n",
        "*   **varidx2fidx** is a dictionary containing, for each variable, the indexes of the grounding of the formulas that the variable makes true\n",
        "*   **stat** is a dictionary containing, for each grounding of each formula, the numÂ­ber of times that each value of the variable makes that grounding true\n",
        "*   **evidence_mask** is a masking array containing the truth value of the variables\n"
      ],
      "metadata": {
        "id": "20dpCESx-yKE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qLihyFid_9C"
      },
      "source": [
        "var_dict = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/neoplasm25_variables.pt')\n",
        "nn_inputs = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/neoplasm25_inputs.pt')\n",
        "gidx_mat = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/neoplasm25_gidxmat.pt')\n",
        "varidx2fidx = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/neoplasm25_varidx2fidx.pt')\n",
        "stat = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/neoplasm25_stat.pt')\n",
        "evidence_mask = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/neoplasm25_evidence_mask.pt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the ground truth, validation and test set"
      ],
      "metadata": {
        "id": "k05UgYkN-wp0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsbKQciyyO8O"
      },
      "source": [
        "type_true = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/type_true.pt')\n",
        "link_true = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/train/link_true.pt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz5MdkmMdJMF"
      },
      "source": [
        "val_inputs = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/val/neoplasm25_val_inputs.pt')\n",
        "val_true = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/val/neoplasm25_val_true.pt')\n",
        "type_val_true = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/val/neoplasm25_type_val_true.pt')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN6tVDhmUYFB"
      },
      "source": [
        "test_inputs = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/test/neoplasm25_test_inputs.pt')\n",
        "link_test_true = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/test/neoplasm25_link_test_true.pt')\n",
        "type_test_true = torch.load(base_dir + '/abstrct/data_notebook/neoplasm25/test/neoplasm25_type_test_true.pt')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate the two dictionaries"
      ],
      "metadata": {
        "id": "a9BgJWk5-mJL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feJZJ1Oc_YBF"
      },
      "source": [
        "link_dict = {}\n",
        "\n",
        "for i in range(14086):\n",
        "    link_dict[i] = var_dict[i]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wDseb7y_YBI"
      },
      "source": [
        "type_dict = {}\n",
        "\n",
        "for i in range(16332, 16332+2246):\n",
        "    type_dict[i-16332] = var_dict[i]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### glaucoma25\n",
        "Load the glaucoma25 set for testing"
      ],
      "metadata": {
        "id": "c-XTtAqf8gkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gla_inputs = torch.load(base_dir + '/abstrct/data_notebook/glaucoma25/gla_inputs.pt')\n",
        "type_gla_true = torch.load(base_dir + '/abstrct/data_notebook/glaucoma25/type_gla_true.pt')\n",
        "link_gla_true = torch.load(base_dir + '/abstrct/data_notebook/glaucoma25/link_gla_true.pt')"
      ],
      "metadata": {
        "id": "9EkZfwuz8c2D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mixed25\n",
        "Load the mixed25 set for testing"
      ],
      "metadata": {
        "id": "Gs3UN6PL8iZS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoKIQ4KicbgQ"
      },
      "source": [
        "mix_inputs = torch.load(based_dir + '/abstrct/data_notebook/mixed25/mix_inputs.pt')\n",
        "type_mix_true = torch.load(based_dir + '/abstrct/data_notebook/mixed25/type_mix_true.pt')\n",
        "link_mix_true = torch.load(based_dir + '/abstrct/data_notebook/mixed25/link_mix_true.pt')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUaUI5c3vlHs"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the two neural network for the tasks"
      ],
      "metadata": {
        "id": "loVDTkWh3bWr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge4MnvA_vkTy"
      },
      "source": [
        "class TypeNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TypeNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(25, 10)\n",
        "        self.fc2 = nn.Linear(10, 20)\n",
        "        self.fc3 = nn.Linear(20, 10)\n",
        "        self.fc4 = nn.Linear(10, 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.dropout(self.activation(self.fc1(input)))\n",
        "        output = self.dropout(self.activation(self.fc2(output)))\n",
        "        output = self.dropout(self.activation(self.fc3(output)))\n",
        "        output = self.fc4(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class LinkNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinkNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(50, 10)\n",
        "        self.fc2 = nn.Linear(10, 20)\n",
        "        self.fc3 = nn.Linear(20, 10)\n",
        "        self.fc4 = nn.Linear(10, 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.dropout(self.activation(self.fc1(input)))\n",
        "        output = self.dropout(self.activation(self.fc2(output)))\n",
        "        output = self.dropout(self.activation(self.fc3(output)))\n",
        "        output = self.fc4(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfFR0IQQUgE9"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT8mYC8FUgE-"
      },
      "source": [
        "def var_pl(varidx, wt):\n",
        "    '''\n",
        "    Computes the pseudo-likelihoods for the given variable under weights w. \n",
        "    '''\n",
        "\n",
        "    values = 2\n",
        "    var = var_dict[varidx]\n",
        "    name, wt_idx1, wt_idx2, wt_idx3 = var\n",
        "\n",
        "    # if the predicate is a Feature Predicate return the tensor [0, 1]\n",
        "    if name == 'Text':\n",
        "        return torch.tensor([0, 1], dtype=torch.float)\n",
        "\n",
        "    if name == 'Link':        \n",
        "        wt_idx = gidx_mat[wt_idx1][wt_idx2]-1\n",
        "    \n",
        "    gfs = varidx2fidx.get(varidx)\n",
        "    if gfs is None: \n",
        "        # no list was saved, so the truth of all formulas is unaffected by the variable's value\n",
        "        # uniform distribution applies\n",
        "        p = 1.0 / values\n",
        "        return p * torch.ones(values, device=device)\n",
        "    sums = torch.zeros(values, device=device)\n",
        "    for fidx, groundings in gfs.items():\n",
        "        for gidx in groundings:\n",
        "            for validx, n in enumerate(stat[fidx][gidx][varidx]):\n",
        "                if ftype[fidx] == 'hard': \n",
        "                    # penalize the prob mass of every value violating a hard constraint\n",
        "                    if n == 0: \n",
        "                        if fidx == 0:\n",
        "                            sums[validx] = sums[validx] - 1000 * wt[fidx][wt_idx1][wt_idx3]\n",
        "                        if fidx == 1:\n",
        "                            sums[validx] = sums[validx] - 1000 * wt[fidx][wt_idx][wt_idx3]\n",
        "                else:\n",
        "                    if fidx == 0:\n",
        "                        sums[validx] = sums[validx] + n * wt[fidx][wt_idx1][wt_idx3]\n",
        "                    if fidx == 1:\n",
        "                        sums[validx] = sums[validx] + n * wt[fidx][wt_idx][wt_idx3]\n",
        "\n",
        "    return sums"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDQEX-Crdwo9"
      },
      "source": [
        "def compute_pls(wt):\n",
        "    '''\n",
        "    Computes the pseudo-likelihoods for all the variables based on the\n",
        "    weights wt which constitutes the outputs of the neural networks\n",
        "    '''\n",
        "    pls = []\n",
        "    pls.append(torch.zeros((2246,2), device=device))\n",
        "    pls.append(torch.zeros((14086,2), device=device))\n",
        "    for varidx in type_dict:\n",
        "        pls[0][varidx] = var_pl(varidx+16332, wt)\n",
        "    for varidx in link_dict:\n",
        "        pls[1][varidx] = var_pl(varidx, wt)\n",
        "    \n",
        "    return pls"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrgWXi5hd4jx"
      },
      "source": [
        "def grad(w):\n",
        "    '''\n",
        "    Computes the gradient taking into consideration the pseudo-likelihoods\n",
        "    '''\n",
        "    pls = compute_pls(w)\n",
        "    grad = torch.zeros(len(nnformulas), dtype=torch.float64)\n",
        "    for fidx, groundval in stat.items():\n",
        "        if fidx > 1:\n",
        "            break\n",
        "        for gidx, varval in groundval.items():\n",
        "            for varidx, counts in varval.items():\n",
        "                var = var_dict[varidx]\n",
        "                name, _, _, evidx = var\n",
        "                g = counts[evidx]\n",
        "                if name == 'Text':\n",
        "                    continue\n",
        "                if name == 'Type':\n",
        "                    plsidx = 0\n",
        "                    varidx -= 16332\n",
        "                if name == 'Link':\n",
        "                    plsidx = 1\n",
        "                for i, val in enumerate(counts):\n",
        "                    g -= val * pls[plsidx][varidx][i]\n",
        "                grad[fidx] += g\n",
        "    \n",
        "    return grad"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rufp8RLVUgE_"
      },
      "source": [
        "def forward():\n",
        "    '''\n",
        "    Computes the forward step of the nural networks\n",
        "    '''\n",
        "    wt = []\n",
        "    for fidx, nn in enumerate(nnformulas):\n",
        "        wt.append(nn(nn_inputs[fidx]))\n",
        "\n",
        "    return wt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-W4ktSjUgFA"
      },
      "source": [
        "def train(optimizer, criterion, grad_mod):\n",
        "    '''\n",
        "    Computes an epoch of the full training step\n",
        "    '''\n",
        "    for model in nnformulas:\n",
        "        model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    preds = forward()\n",
        "    # print(preds[1])\n",
        "    loss1 = criterion[0](preds[0], type_true)\n",
        "    loss2 = criterion[1](preds[1], link_true)\n",
        "    loss = loss1+loss2\n",
        "\n",
        "    loss.backward()\n",
        "    if (grad_mod):\n",
        "        gradient = grad(preds)\n",
        "        for fidx, nn in enumerate(nnformulas):\n",
        "            for par in nn.parameters():\n",
        "                par.grad *= gradient[fidx]\n",
        "\n",
        "    optimizer.step()\n",
        "    return loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KHJC_UJUgFB"
      },
      "source": [
        "def evaluate():\n",
        "    '''\n",
        "    Evaluate the model\n",
        "    '''\n",
        "    for model in nnformulas:\n",
        "        model.eval()\n",
        "\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for fidx, nn in enumerate(nnformulas):\n",
        "            pred.append(nn(val_inputs[fidx]))\n",
        "        y_link = pred[1]\n",
        "        y_link_pred = y_link.argmax(dim=1)\n",
        "        f1_link = f1_score(val_true, y_link_pred, average='macro', labels=[1])\n",
        "\n",
        "        y_type = pred[0]\n",
        "        y_type_pred = y_type.argmax(dim=1)\n",
        "        f1_type = f1_score(type_val_true, y_type_pred, average='macro')\n",
        "\n",
        "        return f1_link, f1_type"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRJE8X3bUgFB"
      },
      "source": [
        "def training_loop(epochs, optimizer, criterion, pretrain=None,\n",
        "                   early_stopping=True, early_stopping_epochs=1000, verbose=False):\n",
        "    '''\n",
        "    Computes the training algorithm with all the epochs and evaluate the model\n",
        "    after each training step. It is possible to pretrain the model for a number\n",
        "    of epochs given by the pretrain param.\n",
        "    '''\n",
        "    start_train = time.time()\n",
        "    best_val_f1 = 0\n",
        "    best_epoch = 0\n",
        "    epochs_no_improve = 0\n",
        "    best_params = copy.deepcopy(nnformulas.state_dict())\n",
        "    grad_mod = False\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_epoch = time.time()\n",
        "        \n",
        "        if (pretrain):\n",
        "            if (epoch > pretrain):\n",
        "                grad_mod = True\n",
        "        else:\n",
        "            grad_mod = True\n",
        "\n",
        "        loss_train = train(optimizer, criterion, grad_mod)\n",
        "        train_time = time.time()\n",
        "\n",
        "        val_f1_link, val_f1_type = evaluate()\n",
        "\n",
        "        end_epoch = time.time()\n",
        "\n",
        "        # Early stopping\n",
        "        if val_f1_link > best_val_f1:\n",
        "            epochs_no_improve = 0\n",
        "            best_val_f1 = val_f1_link\n",
        "            best_params = copy.deepcopy(nnformulas.state_dict())\n",
        "            best_epoch = epoch\n",
        "        else: \n",
        "            epochs_no_improve += 1\n",
        "        \n",
        "        if early_stopping and epochs_no_improve == early_stopping_epochs:\n",
        "            if verbose:\n",
        "                print('Early stopping!' )\n",
        "            break\n",
        "\n",
        "        if verbose and (epoch+1)%1 == 0:\n",
        "            print(f'Epoch: {epoch+1} '\n",
        "                    f' Loss: Train = [{loss_train:.4f}] '\n",
        "                    f' F1: Val_Link = [{val_f1_link:.4f}] Val_Type = [{val_f1_type:.4f}] '\n",
        "                    f' Time one epoch (s): {end_epoch-start_epoch:.4f} ')\n",
        "\n",
        "    end_train= time.time()\n",
        "    print(f\"Best epoch {best_epoch+1}, F1_macro: {best_val_f1:.4f}\")\n",
        "    print(f'Time for training: {end_train-start_train}')\n",
        "\n",
        "    return best_val_f1, best_epoch, best_params"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2oQUadFUgFC"
      },
      "source": [
        "# Define the types of formulas (in this case the first two are neural formulas and the other two are hard constraints)\n",
        "ftype = ['nn', 'nn', 'hard', 'hard']\n",
        "nnformulas = torch.nn.ModuleList()\n",
        "nnformulas.append(TypeNetwork())\n",
        "nnformulas.append(LinkNetwork())\n",
        "\n",
        "optimizer = torch.optim.Adam(nnformulas.parameters(), lr=0.001)\n",
        "criterion = [nn.CrossEntropyLoss(), nn.CrossEntropyLoss(weight=torch.tensor([0.1, 0.9]))]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zM1hOrQUgFD"
      },
      "source": [
        "best_valid_f1, best_epoch, best_params = training_loop(epochs=1000, optimizer=optimizer, criterion=criterion, \n",
        "                                                       pretrain=100, early_stopping=True, early_stopping_epochs=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAQTdVCbqk8k"
      },
      "source": [
        "# Train ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729761b4-be20-4760-bd43-cb2ef2df0799",
        "id": "7EBj3V3CXqTr"
      },
      "source": [
        "n_models=20\n",
        "best_models = []\n",
        "for i in range(n_models):\n",
        "    nnformulas = torch.nn.ModuleList()\n",
        "    nnformulas.append(TypeNetwork())\n",
        "    nnformulas.append(LinkNetwork())\n",
        "    \n",
        "    optimizer = torch.optim.Adam(nnformulas.parameters(), lr=0.001)\n",
        "    criterion = [nn.CrossEntropyLoss(), nn.CrossEntropyLoss(weight=torch.tensor([0.1, 0.9]))]\n",
        "    \n",
        "    print(f'Model {i}')\n",
        "    best_valid_f1, best_epoch, best_params = training_loop(epochs=1000, optimizer=optimizer, criterion=criterion, \n",
        "                                                           pretrain=None, early_stopping=True, early_stopping_epochs=100, verbose=False)\n",
        "    best_models.append(best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0\n",
            "Best epoch 1, F1_macro: 0.4402\n",
            "Time for training: 240.01757836341858\n",
            "Model 1\n",
            "Best epoch 20, F1_macro: 0.4233\n",
            "Time for training: 290.90355253219604\n",
            "Model 2\n",
            "Best epoch 4, F1_macro: 0.4563\n",
            "Time for training: 248.33392453193665\n",
            "Model 3\n",
            "Best epoch 2, F1_macro: 0.4089\n",
            "Time for training: 243.1462481021881\n",
            "Model 4\n",
            "Best epoch 4, F1_macro: 0.4468\n",
            "Time for training: 245.45780754089355\n",
            "Model 5\n",
            "Best epoch 1, F1_macro: 0.4464\n",
            "Time for training: 239.87665963172913\n",
            "Model 6\n",
            "Best epoch 1, F1_macro: 0.4474\n",
            "Time for training: 238.34864115715027\n",
            "Model 7\n",
            "Best epoch 1, F1_macro: 0.4413\n",
            "Time for training: 238.35264563560486\n",
            "Model 8\n",
            "Best epoch 4, F1_macro: 0.4336\n",
            "Time for training: 245.46652698516846\n",
            "Model 9\n",
            "Best epoch 5, F1_macro: 0.4605\n",
            "Time for training: 246.58912706375122\n",
            "Model 10\n",
            "Best epoch 1, F1_macro: 0.4382\n",
            "Time for training: 236.7871265411377\n",
            "Model 11\n",
            "Best epoch 9, F1_macro: 0.4457\n",
            "Time for training: 254.3463168144226\n",
            "Model 12\n",
            "Best epoch 2, F1_macro: 0.4466\n",
            "Time for training: 238.9087495803833\n",
            "Model 13\n",
            "Best epoch 1, F1_macro: 0.3987\n",
            "Time for training: 237.8864278793335\n",
            "Model 14\n",
            "Best epoch 4, F1_macro: 0.4572\n",
            "Time for training: 246.79122686386108\n",
            "Model 15\n",
            "Best epoch 4, F1_macro: 0.4548\n",
            "Time for training: 242.62768650054932\n",
            "Model 16\n",
            "Best epoch 1, F1_macro: 0.4601\n",
            "Time for training: 236.049476146698\n",
            "Model 17\n",
            "Best epoch 3, F1_macro: 0.4484\n",
            "Time for training: 241.7773756980896\n",
            "Model 18\n",
            "Best epoch 1, F1_macro: 0.4613\n",
            "Time for training: 237.05747866630554\n",
            "Model 19\n",
            "Best epoch 4, F1_macro: 0.4412\n",
            "Time for training: 242.9725480079651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sLxD5oVUcwQ"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the single model"
      ],
      "metadata": {
        "id": "iJ9E8dni72nu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEwD835YxTlr"
      },
      "source": [
        "nnformulas = torch.nn.ModuleList()\n",
        "nnformulas.append(TypeNetwork())\n",
        "nnformulas.append(LinkNetwork())\n",
        "nnformulas.load_state_dict(best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB03qXHQl3xj"
      },
      "source": [
        "print('TYPE')\n",
        "nnformulas[0].eval()\n",
        "with torch.no_grad():\n",
        "    pred = nnformulas[0](test_inputs[0])\n",
        "    round_pred = pred.argmax(dim=1)\n",
        "    print(classification_report(type_test_true, round_pred))\n",
        "\n",
        "print('LINK')\n",
        "nnformulas[1].eval()\n",
        "with torch.no_grad():\n",
        "    pred = nnformulas[1](test_inputs[1])\n",
        "    round_pred = pred.argmax(dim=1)\n",
        "    print(classification_report(link_test_true, round_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalutate the ensemble with the average of scores (AVG) and the major voting (MAJ) "
      ],
      "metadata": {
        "id": "ly3jIlFvwje4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pi5FcKEDP4z"
      },
      "source": [
        "# Model used in the thesis \n",
        "best_models = torch.load(base_dir + '/abstrct/data_notebook/trained_models/ens20_prebest_es100.pt')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpCL7-7avLSa",
        "outputId": "c8bebbaa-0207-4504-e4d0-36156b41ba05"
      },
      "source": [
        "preds_type = []\n",
        "preds_link = []\n",
        "\n",
        "for par in best_models:\n",
        "    eval_model = torch.nn.ModuleList()\n",
        "    eval_model.append(TypeNetwork())\n",
        "    eval_model.append(LinkNetwork())\n",
        "    eval_model.load_state_dict(par)\n",
        "    \n",
        "    eval_model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds_type.append(eval_model[0](test_inputs[0]))\n",
        "        preds_link.append(eval_model[1](test_inputs[1]))\n",
        "\n",
        "print('TYPE_AVG')\n",
        "pred_type_avg = torch.stack(preds_type).mean(dim=0)\n",
        "round_pred_type_avg = pred_type_avg.argmax(dim=1)\n",
        "print(classification_report(type_test_true, round_pred_type_avg))\n",
        "\n",
        "print('LINK_AVG')\n",
        "pred_link_avg = torch.stack(preds_link).mean(dim=0)\n",
        "round_pred_link_avg = pred_link_avg.argmax(dim=1)\n",
        "print(classification_report(link_test_true, round_pred_link_avg))\n",
        "\n",
        "print('TYPE_MAJ')\n",
        "pred_type_maj = torch.stack(preds_type).argmax(dim=2).sum(dim=0)\n",
        "round_pred_type_maj = (pred_type_maj > len(best_models)/2).int()\n",
        "print(classification_report(type_test_true, round_pred_type_maj))\n",
        "\n",
        "print('LINK_MAJ')\n",
        "pred_link_maj = torch.stack(preds_link).argmax(dim=2).sum(dim=0)\n",
        "round_pred_link_maj = (pred_link_maj > len(best_models)/2).int()\n",
        "print(classification_report(link_test_true, round_pred_link_maj))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TYPE_AVG\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.69      0.73       248\n",
            "           1       0.84      0.88      0.86       438\n",
            "\n",
            "    accuracy                           0.81       686\n",
            "   macro avg       0.80      0.79      0.79       686\n",
            "weighted avg       0.81      0.81      0.81       686\n",
            "\n",
            "LINK_AVG\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.81      0.88      3956\n",
            "           1       0.27      0.63      0.37       424\n",
            "\n",
            "    accuracy                           0.80      4380\n",
            "   macro avg       0.61      0.72      0.63      4380\n",
            "weighted avg       0.89      0.80      0.83      4380\n",
            "\n",
            "TYPE_MAJ\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.73      0.75       248\n",
            "           1       0.85      0.87      0.86       438\n",
            "\n",
            "    accuracy                           0.82       686\n",
            "   macro avg       0.81      0.80      0.80       686\n",
            "weighted avg       0.82      0.82      0.82       686\n",
            "\n",
            "LINK_MAJ\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.82      0.88      3956\n",
            "           1       0.27      0.61      0.37       424\n",
            "\n",
            "    accuracy                           0.80      4380\n",
            "   macro avg       0.61      0.72      0.63      4380\n",
            "weighted avg       0.89      0.80      0.83      4380\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Krippendorff evaluation"
      ],
      "metadata": {
        "id": "FOgUhIyopHLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure the agreement between the models of the ensemble using the Krippendorff's alpha"
      ],
      "metadata": {
        "id": "qxoDJVvhFnnw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PATT-sc9_zik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041bf4d9-a507-4d9e-9475-a32f6c5f565e"
      },
      "source": [
        "!pip install krippendorff"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting krippendorff\n",
            "  Downloading krippendorff-0.5.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from krippendorff) (1.19.5)\n",
            "Installing collected packages: krippendorff\n",
            "Successfully installed krippendorff-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_6iAfyP_2tm"
      },
      "source": [
        "import krippendorff"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aNP0ktRCSE8",
        "outputId": "f9802295-447b-4b6f-fd39-f45c6fe09982"
      },
      "source": [
        "rounded_pred_type = torch.stack(preds_type).argmax(dim=2)\n",
        "krippendorff.alpha(reliability_data=np.array(rounded_pred_type))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8623505031839513"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A4QyNut_3pi",
        "outputId": "c70f179d-b2f9-4789-9577-6626031eebfc"
      },
      "source": [
        "rounded_pred_link = torch.stack(preds_link).argmax(dim=2)\n",
        "krippendorff.alpha(reliability_data=np.array(rounded_pred_link))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7000472917662675"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}